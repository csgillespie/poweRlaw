\documentclass[a4paper,justified,openany]{tufte-handout}
\setcounter{secnumdepth}{2}

\usepackage{microtype}
% -------------------------------------------------------------------------------

%\usepackage{cite} % Make references as [1-4], not [1,2,3,4]
\usepackage{url}  % Formatting web addresses  
%\usepackage[utf8]{inputenc} %unicode support
%\usepackage{epsfig}
\usepackage{color,hyperref,comment, booktabs}
\urlstyle{rm}
\usepackage{algorithmic, algorithm}
\newcommand{\cc}{\texttt}
\newcommand{\xmin}{x_{\min}}

\newcommand{\note}[1]{{\color{red}#1}}

\usepackage{etoolbox}
\makeatletter
\preto{\@verbatim}{\topsep=-20pt \partopsep=0pt }
\makeatother

\date{Last updated: \today}  % if the \date{} command is left out, the current date will be used

\title{The poweRlaw package}
\author[Colin S. Gillespie]{Colin S. Gillespie}
\date{Last updated: \today}

<<echo=FALSE>>=
opts_chunk$set(prompt = FALSE,fig.path='graphics/', fig.align='center',fig.lp="")
options(width=75)
knit_theme$set(knit_theme$get()[7])
setnicepar = function(...)  par(mar=c(3,3,2,1), 
                  mgp=c(2,0.4,0), tck=-.01,
                  cex.axis=0.9, las=1, ...)
set.seed(1)
@

\begin{document}
\maketitle
 \begin{abstract}
The \verb$poweRlaw$ package provides code to fit discrete and continuous power-law distributions. 
The fitting procedure follows the method detailed in Clauset \textit{et al.}\cite{clauset2009}. The scaling coefficient, $\alpha$, is obtained by maximising the likelihood. The cut-off value, $\xmin$, is estimated by minimising the Kolmogorov-Smirnoff statistic.

Future versions of this package will allow other heavy tailed distributions to be fitted.
\end{abstract}

\section{Installation}

% The package can be installed from CRAN using the standard command:
% <<eval=FALSE>>=
% install.packages("poweRlaw")
% @
% \noindent from any machine with an internet connection. 

The package is hosted on github.\sidenote{The intention is eventually host this package on CRAN.} The package can be installed using the \cc{devtools} package:\sidenote{If use Windows, you need to install the \texttt{Rtools} package first.}
<<eval=FALSE>>=
install.packages("devtools")
library(devtools)
install_github("poweRlaw", "csgillespie", subdir="pkg")
@
\noindent Once installed, the package can be loaded ready for use with the standard \cc{library} command
<<>>=
library(poweRlaw)
@


\section{Accessing documentation}

I have tried to ensure that the package and all associated functions and datasets are properly documented with runnable examples. The command
<<results='hide'>>=
help(package="poweRlaw")
@
\noindent will give a brief overview of the package and a complete list of all functions. The list of vignettes associated with the package can be obtained with
<<results='hide'>>=
vignette(package="poweRlaw")
@
\noindent At the time of writing, \emph{this} vignette is the only one available, and can be accessed from the R command line with
<<eval=FALSE>>=
vignette("poweRlaw", package="poweRlaw")
@
\noindent Help on functions can be obtained using the usual R mechanisms. For example, help on the function \verb$rpldis$ can be obtained with
<<message=FALSE,results='hide', tidy=FALSE>>=
?rpldis
@
\noindent and the associated example can be run with
<<results='hide',fig.keep='none'>>=
example(rpldis)
@
\noindent A list of demos and data sets associated with the package can be obtained with
<<eval=FALSE>>=
demo(package="poweRlaw")
data(package="poweRlaw")
@
\noindent For example, the Moby dick data set can be load using\marginnote{The package also contains the data set \texttt{moby\_sample}. This data set is 2000 randomly sampled values from the larger \cc{moby} data set.}
<<>>=
data(moby)
@
\noindent After running this command, the vector \verb$moby$ will be accessible, and can be examined by typing
<<results='hide'>>=
moby
@
\noindent at the R command prompt.


\section{Example: Word frequency in Moby Dick}

This example investigates the frequency of occurrence of unique words in the novel Moby Dick by Herman Melville\cite{clauset2009,newman2005}. The data can be downloaded from
\begin{center}
\url{http://tuvalu.santafe.edu/~aaronc/powerlaws/data.htm}
\end{center}
\noindent or loaded directly
<<>>=
data(moby)
@

\subsection{Fitting a discrete power-law}

To fit a discrete power-law, we create a discrete power-law object, \texttt{displ}
<<>>=
m_m = displ$new(moby)
@
\noindent Initially the lower cut-off, $\xmin$ is set to the smallest $x$ value and the scaling parameter, \texttt{alpha}, is set to \texttt{NULL}
<<tidy=FALSE>>=
m_m$getXmin()
m_m$getPars()
@
\noindent The distribution object also has standard setters
<<>>=
m_m$setXmin(5)
m_m$setPars(2)
@
\noindent For a given $\xmin$ value, we can estimate the corresponding $\alpha$ value using its maximum likelihood estimator (mle)\marginnote{Instead of using the mle, we could instead do a parameter scan:\\ \texttt{\mbox{estimate\_pars(m\_m, pars=seq(2, 3, 0.1))}}}
<<>>=
estimate_pars(m_m)
@
\noindent To estimate the lower bound, we minimise the distance between the data and the fitted model CDF, that is
\[
D(x) = \max_{x \ge \xmin} \vert S(x) - P(x) \vert
\]
\noindent where $S(x)$ is the data CDF and $P(x)$ is the theoretical CDF. The value $D(x)$ is known as the Kolmogorov-Smirnov statistic. Our estimate of $\xmin$ is then the value of $x$ that minimises $D(x)$:
\begin{marginfigure}
\centering
\includegraphics[width=\textwidth]{graphics/figure1-crop}
\caption{Plot of the data CDF for the Moby Dick data set. This corresponds to figure 6.1(a) in Clausett, 2009. Plot of data CDF with line of best fit.}
\end{marginfigure}
<<>>=
(est = estimate_xmin(m_m))
@
\noindent We can then set parameters of power-law distribution to the "optimal" values
<<>>=
m_m$setXmin(est)
@
\noindent All distribution objects  have generic plot methods:\sidenote{Generic \texttt{lines} and \texttt{points} functions are also available.}
<<fig.keep='none'>>=
##Plot the data (from xmin)
plot(m_m)
##Add in the fitted distribution
lines(m_m, col=2)
@
\noindent When calling the \texttt{plot} and \texttt{lines} function, the data plotted is actually invisibly returned, i.e.
<<fig.keep='none'>>=
dd = plot(m_m)
head(dd, 3)
@



<<echo=FALSE>>=
pdf("graphics/figure1.pdf", width=4, height=4)
setnicepar()
plot(m_m, xlab="x", ylab="CDF")
grid()
lines(m_m, col=2)
sink=dev.off()
system("pdfcrop graphics/figure1.pdf")
data(bootstrap_moby)
bs = bootstrap_moby
@

\subsection{Quantifying $\xmin$ uncertainty}

Clausett, \textit{el al}, 2009 recommend a bootstrap procedure to estimate the uncertainty in $\xmin$. Essentially, an estimate of parameter uncertainty is obtained by generating multiple data sets (with parameters $\xmin$ and $\alpha$) and then "re-inferring" the model parameters. The algorithm is detailed in Algorithm 1.\sidenote{Algorithm 1 can easily be extended for other distributions.}
\begin{table}[t]
\centering
  \begin{tabular}{@{}ll@{}}
    \hline
    \multicolumn{2}{l}{\textbf{Algorithm 1:} Estimating the uncertainty in \texttt{xmin}}\\
    \hline
    {\small 1:} & Calculate point estimates $\xmin$ and the scaling parameter $\alpha$. \\
    {\small 2:} & Set $n_1$ equal to the number of values below \texttt{xmin}. \\
    {\small 3:} & Set $n_2 = n - n_1$.\\
    {\small 4:} & \textbf{for} \texttt{i} in \texttt{1:B}:\\
    {\small 5:} & $\quad$ Simulate $n_1$ values from a discrete uniform distribution: $U(1, \xmin)$ and $n_2$ values from a discrete \\
    & $\quad$ power-law (with parameter $\alpha$).\\
    {\small 6:} & $\quad$ Estimate $\xmin$ and $\alpha$ using the Kolmogorov-Smirnoff statistic.\\
    {\small 7:} & \textbf{end for} \\
    \hline
  \end{tabular}
\end{table}  

When $\alpha$ is close to one, this algorithm can be particularly time consuming to run, for two reasons:
\begin{enumerate}
\item When generating random numbers from the discrete power-law distribution, extreme values are highly possible, i.e. values greater than $10^8$. Hence, when generating the random numbers, all numbers larger than $10^5$ are generated using a continuous approximation.
\item To calculate the Komologorov-Smirnov statistic, we need explore the state space. It is computationally infeasible to explore the entire state space when $\max(x) >> 10^5$. So to this algorithm feasible, we explore two state space. The first, 
\[
\xmin, \xmin+1, \xmin+2, \ldots, 10^5
\]
and combine it with an additional $10^5$ values from
\[
10^5, \ldots, \max(x)
\]
\end{enumerate}
The bootstrapping procedure, steps 4 -- 7, can be run in parallel. To estimate the uncertainty with the \cc{moby} data set, we use
<<eval=FALSE>>=
##This takes a while
bs = bootstrap_xmin(m_m, no_of_sims=1000, threads=1)
@
\begin{marginfigure}
\centering
\includegraphics[width=\textwidth]{graphics/figure2-crop}
\caption{Histograms of the bootstrap results.}\label{F2}
\end{marginfigure}
\noindent The object returned from the bootstrap procedure contains three elements
\begin{itemize}
\item A $p$-value .. \verb|bs$p|
\item The original goodness of fit statistic  - \verb|bs$gof|
\item The result of the bootstrap procedure - a data frame with three columns.
\item The average time (in seconds) for a single bootstrap realisation.
\end{itemize}
\noindent The results of the bootstrap are best investigated with histograms
<<fig.keep='none'>>=
hist(bs$bootstraps[,2])
hist(bs$bootstraps[,3])
@
\noindent and a bivariate scatter plot
<<fig.keep='none'>>=
plot(bs$bootstraps[,2], bs$bootstraps[,3])
@
\begin{marginfigure}
\centering
\includegraphics[width=\textwidth]{graphics/figure3-crop}
\caption{Bivariate scatter plot of the bootstrap results. The values of $\xmin$ and $\alpha$ are obviously strongly correlated.}\label{F3}
\end{marginfigure}


<<echo=FALSE>>=
pdf("graphics/figure2.pdf", width=4, height=6)
setnicepar(mfrow=c(2, 1))
hist(bs$bootstraps[,2], xlab="xmin", ylim=c(0, 400), 
     xlim=c(0, 35), main=NULL)
hist(bs$bootstraps[,3], xlab=expression(alpha), 
     ylim=c(0, 400), xlim=c(1.8, 2.1), main=NULL)
sink=dev.off()
system("pdfcrop graphics/figure2.pdf")

pdf("graphics/figure3.pdf", width=4, height=4)
setnicepar(mfrow=c(1,1))
plot(jitter(bs$bootstraps[,2], factor=1.2), bs$bootstraps[,3], 
     xlab="xmin", ylab=expression(alpha), 
     xlim=c(0, 35), ylim=c(1.8, 2.1), cex=0.35)
grid()
sink = dev.off()
system("pdfcrop graphics/figure3.pdf")
@



\section{Distribution objects}

During the Moby Dick example, we created a \texttt{displ} object
<<>>=
m_m = displ$new(moby)
@
\noindent The object \cc{m} has class \cc{displ} and inherits the general \texttt{distribution} class. A list of available distributions is given in table \ref{T1}. 
\begin{table}[h]
  \centering
  \begin{tabular}{@{} llll @{}}
  \toprule
  Distribution & Object name & \# Parameters \\
  \midrule
  Discrete Power-law & \texttt{displ} & 1 \\
  CTN Power-law & \texttt{conpl} & 1 \\
  \bottomrule
  \end{tabular}
  \caption{Available distributions in the power-law package. These objects are all reference classes.}\label{T1}
\end{table}
<<echo=FALSE>>=
m_m$setXmin(est)
@

\noindent All distribution objects list in table \ref{T1} are reference classes.\marginnote{See \texttt{\mbox{?setRefClass}} for further details on references classes.} The key point, is that unlike S4 classes, reference classes have a mutable set. Each distribution object has four fields:
\begin{itemize}
\item \texttt{datatype}: This will be set to \textit{discrete} or \textit{continuous}.
\item \texttt{dat}: a copy of the data.
\item \texttt{xmin}: the lower cut-off $\xmin$.
\item \texttt{pars}: a vector of parameter values.
\item \texttt{internal}: a list of values use in different numerical procedures. This will differ between distribution objects.
\end{itemize}
By using the mutable state, we have  efficient caching of data structures that can be reused. For example, the mle of discrete power-laws uses the statistic:
\[
\sum_{i=\xmin}^n \log(x_i)
\]
This value is calculated once for all values of $\xmin$, then iterated over when estimating $\xmin$. 

All distribution objects have a number of methods available. A list of methods is given in table \ref{T2}. See the associated help files for further details.
\begin{table}[h]
  \centering
  \begin{tabular}{@{} lp{7.5cm} @{}}
    \toprule
    Method Name & Description \\
    \midrule
    \texttt{dist\_cdf} & Cumulative density function\\
    \texttt{dist\_pdf} & Probability density function\\
    \texttt{dist\_rand}& Random numbers generator\\
    \texttt{dist\_data\_cdf} & Data CDF \\
    \texttt{dist\_ll} & Log-likelihood\\
    \texttt{estimate\_xmin} & Estimate the cut-off point and parameter value\\
    \texttt{estimate\_pars} & Estimate of the parameters (conditional on the current $\xmin$ value)\\
    \texttt{bootstrap\_xmin} & Bootstrap procedure\\
    \bottomrule
  \end{tabular}
  \caption{A list of functions for \texttt{distribution} functions. These objects do not change the object states. However, they may not be thread safe. }\label{T2}
\end{table}

<<echo=FALSE, results='hide', message=FALSE, warning=FALSE, error=FALSE>>=
blackouts = try(read.table("blackouts.txt"))
if(class(blackouts) == "try-error")
  blackouts = read.txt("http://goo.gl/BsqnP")
@

\newpage
\begin{marginfigure}
\centering
\includegraphics[width=\textwidth]{graphics/figure4-crop}
\caption{CDF plot of the blackout dataset with line of best fit. Since the minimum value of $x$ is large, we fit a continuous power-law as this is more it efficient.}\label{F4}
\end{marginfigure}

\section{Loading data}

Typically, data is stored in a csv or text file. To use this data, we load it in the usual way\sidenote{The blackouts data set can be obtained from Clauset's website: \url{http://goo.gl/BsqnP} . }
<<eval=FALSE>>=
blackouts = read.table("blackouts.txt")
@
\noindent Distribution objects take vectors as inputs, so
<<>>=
m_bl = conpl$new(blackouts$V1)
@

<<echo=FALSE>>=
est = estimate_xmin(m_bl)
m_bl$setXmin(est)
pdf("graphics/figure4.pdf", width=4, height=4)
setnicepar(mfrow=c(1,1))
plot(m_bl)
lines(m_bl, col=2)
grid()
sink = dev.off()
system("pdfcrop graphics/figure4.pdf")
@



<<echo=FALSE, results='hide', message=FALSE, warning=FALSE, error=FALSE>>=
tc = try(source("plfit.R"))
if(class(tc) == "try-error")
  source("http://tuvalu.santafe.edu/~aaronc/powerlaws/plfit.r")
@





\section{Comparison with the \texttt{plfit} script}

\subsection{The discrete case}

Other implementations of estimating the lower bound can be found at
\begin{center}
\url{http://tuvalu.santafe.edu/~aaronc/powerlaws/}
\end{center}
In particular, the script for estimating $\xmin$ can be loaded using
<<eval=FALSE>>=
source("http://tuvalu.santafe.edu/~aaronc/powerlaws/plfit.r")
@
\noindent The results are directly comparable to the poweRlaw package. For example, if we look consider the Moby Dick data set again:
<<>>=
plfit(moby)
@
\noindent Notice that the results are slightly different. This is because the \cc{plfit} by default does a parameter scan over the range
\[
1.50, 1.51, 1.52, \ldots, 2.49, 2.50
\]
\noindent To exactly replicate the results, we could use
<<results='hide', eval=FALSE>>=
estimate_xmin(m_m, pars=seq(1.5, 2.5, 0.01))
@

\subsection{The continuous case}

The \texttt{plfit} script also fits continuous power-laws. Again the results are comparable. First we generate one thousand random numbers from the continuous power-law with parameters $\alpha = 2.5$ and $\xmin = 10.0$
<<>>=
r = rplcon(1000, 10, 2.5)
@
\noindent The \texttt{plfit} automatically detects if the data is continuous
<<>>=
plfit(r)
@
\noindent Fitting with the \texttt{poweRlaw} package gives the same values
<<>>=
m_r = conpl$new(r)
(est = estimate_xmin(m_r))
@
\noindent Of course, using the \texttt{poweRlaw} package, we can easily plot the data
\begin{marginfigure}
\centering
\includegraphics[width=\textwidth]{graphics/figure5-crop}
\caption{CDF plot of one thousand random numbers generated from a power-law with parameters $\alpha=2.5$ and $\xmin = 10$. The line of best fit is also shown.}\label{F5}
\end{marginfigure}
<<fig.keep='none'>>=
m_r$setXmin(est)
plot(m_r)
lines(m_r, col=2)
@
\noindent to get figure \ref{F5}.

<<echo=FALSE>>=
pdf("graphics/figure5.pdf", width=4, height=4)
setnicepar(mfrow=c(1,1))
plot(m_r)
lines(m_r, col=2)
grid()
sink = dev.off()
system("pdfcrop graphics/figure5.pdf")
@



\clearpage


\bibliography{poweRlaw}
\bibliographystyle{plainnat}


\clearpage

\section*{Package and R version}

\begin{table}
\centering
\begin{tabular}{@{} llll @{}}
\toprule
Package & Version\\
\midrule
parallel & \Sexpr{packageDescription("parallel")$Version}\\
poweRlaw & \Sexpr{packageDescription("poweRlaw")$Version}\\
VGAM & \Sexpr{packageDescription("VGAM")$Version}\\
\bottomrule
\end{tabular}
\caption{A list of packages and versions used.}\label{A1}
\end{table}

<<>>=
version
@



\end{document}

<<echo=FALSE, eval=TRUE>>=
##Used to generate the figures for github
setwd("../graphics/")
ppi = 300
png("figure1.png", width=6*ppi, height=4*ppi, res=ppi)
setnicepar(mfrow=c(1, 2))
plot(m_m, xlab="x", ylab="CDF")
lines(m_m, col=2, lty=2)
grid()
plot(m_bl, xlab="x", ylab="CDF")
lines(m_bl, col=2, lty=2)
grid()
sink = dev.off()

png("figure2.png", width=6*ppi, height=4*ppi, res=ppi)
setnicepar(mfrow=c(1,2))
hist(bs$bootstraps[,2], xlab="xmin", ylim=c(0, 400), 
     xlim=c(0, 35), main=NULL)
grid()
hist(bs$bootstraps[,3], xlab=expression(alpha), 
     ylim=c(0, 400), xlim=c(1.8, 2.1), main=NULL)
grid()
sink=dev.off()


setwd("../vignettes/")
@

       
       
       
       
       
       
       
       
       
       
       
       
       
       


% eof